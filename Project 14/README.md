# Movie Sentiment Analysis with Natural Language Processing

## Project Description
Film Junky Union, a new community for classic film enthusiasts, is working on a system to filter and categorize film reviews. The primary objective is to train a model capable of automatically detecting negative reviews. Using the IMDB movie review dataset with polarity labeling, the task is to develop a model that can accurately classify reviews as positive or negative. The model must achieve a minimum F1 score of 0.85 to meet the project's requirements.

## Data Description
The data obtained from Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, dan Christopher Potts. (2011). Learning Word Vectors for Sentiment Analysis. The 49th Annual Meeting of the Association for Computational Linguistics (ACL 2011).

Column description:
- `review`: review text
- `pos`: target, '0' for negative dan '1' for positive
- `ds_part`: 'train'/'test' data

## Methodology
- Data Overview
- Explorative Data Analysis
- Evaluation Procedure
  - Normalization
  - Separate dataset into train and test data
- Model Training and Review
  - Constant
  - NLTK, TF-IDF, and Linear Regression
  - NLTK, TF-IDF, and XGBoost
  - spaCy, TF-IDF, and Linear Regression
  - spaCy, TF-IDF, and LGBMClassifier
  - BERT and Linear Regression
  - BERT and CatBoost

## Result
- Model 0 (Constant - 0.67)
  - F1 score is far from the specified threshold value in dummy classifier model
- Model 1.1 (NLTK, TF-IDF, LR - 0.88)
  - LR with NLTK, TF-IDF generates better F1 score than dummy classifier model and passes the threshold value.
- Model 1.2 (NLTK, TF-IDF, XGBoost - 0.85)
  - F1 score of XGB with NLTK, TF-IDF is not better than vectorization results with Logistic Regression, but this model is less prone to overfitting that makes this model better.
- Model 2.1 (Spacy, TF-IDF, LR - 0.88)
  - LR with spacy generates f1 score slightly better than with NLTK vectorization.
- Model 2.2 (Spacy, TF-IDF, LGB - 0.83)
  - LGBM with Spacy, TF-IDF generates F1 score that is not better than LR model with Spacy, TF-IDF.
- Model 3.1 (Bert, LR - 0.86)
  - F1 score that generated by LR model with Bert gives is not significantly different from previous models, but this has better performance from overfitting.
- Model 3.2 (Bert, CatBoost - 0.83)
  - F1 score that generated by CatBoost with Bert gives is not better from previous models, so does the overfitting

***Main Conclusion***
- **Linear Regression** with all vectorization model (NLTK, Spacy, Bert) genarates the best result for F1 score, this model also has good result in terms of overfitting that the others
- The **BERT** model has the best result for overfitting, but the **Spacy** has the best result on F1 Score

## Contact
For any questions or feedback regarding this project, feel free to reach out to me at mahendraalfathfirdaus@gmail.com.
